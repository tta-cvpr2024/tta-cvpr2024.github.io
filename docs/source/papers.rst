Accepted Papers
===============

Our workshop includes a proceedings/archival track and a community/non-archival track.
We are excited to host poster and lightning talk presentations of all contributed papers in both tracks.

**Proceedings**

- P1. MixStyle-Based Contrastive Test-Time Adaptation: Pathway to Domain Generalization.
      Kota Yamashita & Kazuhiro Hotta.
- P2. Fully Test-time Adaptation for Object Detection.
      Xiaoqian Ruan & Wei Tang.
- P3. Test-time Specialization of Dynamic Neural Networks.
      Sam Leroux, Dewant Katare, Aaron Ding, Pieter Simoens.
- P4. ST2ST: Self-Supervised Test-time Adaptation for Video Action Recognition.
      Masud An-Nur Islam Fahim, Mohammed Innat, Jani Boutellier.
- P5. Unknown Sample Discovery for Source Free Open Set Domain Adaptation.
      Chowdhury Sadman Jahan, Andreas Savakis.

**Community**

- C1. Test-time Adaptation for Regression by Subspace Alignment.
      Kazuki Adachi, Shin'ya Yamaguchi, Atsutoshi Kumagai.
- C2. Just Shift It: Test-Time Prototype Shifting for Zero-Shot Generalization with Vision-Language Models.
      Elaine Sui, Xiaohan Wang, Serena Yeung-Levy.
- C3. Persistent Test-time Adaptation in Recurring Testing Scenarios.
      Trung-Hieu Hoang, MinhDuc Vo, Minh N. Do.
- C4. OT-VP: Optimal Transport-guided Visual Prompting for Test-Time Adaptation.
      Yunbei Zhang, Akshay Mehra, Jihun Hamm.
- C5. BECoTTA: Input-dependent Online Blending of Experts for Continual Test-time Adaptation.
      Daeun Lee, Jaehong Yoon, Sung Ju Hwang.
- C6. Adaptive Randomized Smoothing for Certified Multi-Step Defence.
      Shadab Shaikh, Saiyue Lyu, Frederick Shpilevskiy, Evan Shelhamer, Mathias
      Lécuyer.
- C7. A Lost Opportunity for Vision-Language Models: A Comparative Study of Online Test-time Adaptation for Vision-Language Models.
      Mario Döbler, Robert A. Marsden, Tobias Raichle, Bin Yang.

